2025-06-30 03:16:50,939 - INFO - Starting training for task: sst2 with seed: 42
2025-06-30 03:16:50,940 - INFO - Config: CFG(model_name='bert-base-uncased', tasks=['sst2', 'qnli'], train_size=5000, eval_size=1000, device='cuda', epochs=4, batch_train=32, batch_eval=64, save_checkpoints=True, checkpoint_dir='checkpoints', wandb_project='direction_aware_fusion', wandb_entity='your_wandb_entity', wandb_run_name='default_run', wandb=True, log_interval=100, seeds=[42, 123, 456], num_seeds=3, seed=42, confidence_interval=0.95, enable_averaging=False, save_individual_runs=True, aggregation_method='mean')
2025-06-30 03:16:50,968 - INFO - CUDA available: Quadro RTX 8000
2025-06-30 03:16:51,269 - INFO - Tokenizer loaded successfully
2025-06-30 03:16:51,270 - INFO - Loading dataset: glue/sst2
2025-06-30 03:16:52,965 - INFO - Dataset loaded. Train size: 67349, Val size: 872
2025-06-30 03:16:53,528 - INFO - Data preprocessing complete. Train samples: 5000, Val samples: 872
2025-06-30 03:16:53,528 - INFO - Loading model: bert-base-uncased
2025-06-30 03:16:55,960 - INFO - Model loaded and moved to device: cuda
2025-06-30 03:16:55,961 - INFO - Setting up training arguments
2025-06-30 03:16:56,060 - INFO - Setting up trainer
2025-06-30 03:16:56,083 - INFO - Starting training...
{'loss': 0.6719, 'grad_norm': 2.4644882678985596, 'learning_rate': 4.928343949044586e-05, 'epoch': 0.06}
{'loss': 0.518, 'grad_norm': 10.147660255432129, 'learning_rate': 4.8487261146496814e-05, 'epoch': 0.13}
{'loss': 0.4266, 'grad_norm': 7.2632551193237305, 'learning_rate': 4.769108280254777e-05, 'epoch': 0.19}
{'loss': 0.3506, 'grad_norm': 8.259682655334473, 'learning_rate': 4.689490445859872e-05, 'epoch': 0.25}
{'loss': 0.3872, 'grad_norm': 5.301172256469727, 'learning_rate': 4.609872611464968e-05, 'epoch': 0.32}
{'loss': 0.3285, 'grad_norm': 5.415696620941162, 'learning_rate': 4.530254777070064e-05, 'epoch': 0.38}
{'loss': 0.3263, 'grad_norm': 6.737083435058594, 'learning_rate': 4.450636942675159e-05, 'epoch': 0.45}
{'loss': 0.3034, 'grad_norm': 9.275636672973633, 'learning_rate': 4.371019108280255e-05, 'epoch': 0.51}
{'loss': 0.25, 'grad_norm': 6.748648166656494, 'learning_rate': 4.2914012738853507e-05, 'epoch': 0.57}
{'loss': 0.2913, 'grad_norm': 10.484426498413086, 'learning_rate': 4.211783439490446e-05, 'epoch': 0.64}
{'loss': 0.2849, 'grad_norm': 7.149357795715332, 'learning_rate': 4.1321656050955416e-05, 'epoch': 0.7}
{'loss': 0.2862, 'grad_norm': 3.1639134883880615, 'learning_rate': 4.0525477707006374e-05, 'epoch': 0.76}
{'loss': 0.2307, 'grad_norm': 4.5967020988464355, 'learning_rate': 3.9729299363057325e-05, 'epoch': 0.83}
{'loss': 0.3386, 'grad_norm': 7.495598793029785, 'learning_rate': 3.893312101910828e-05, 'epoch': 0.89}
{'loss': 0.3011, 'grad_norm': 7.276641845703125, 'learning_rate': 3.8136942675159234e-05, 'epoch': 0.96}
{'eval_loss': 0.2830081284046173, 'eval_accuracy': 0.8818807339449541, 'eval_runtime': 0.8212, 'eval_samples_per_second': 1061.887, 'eval_steps_per_second': 17.049, 'epoch': 1.0}
{'loss': 0.2338, 'grad_norm': 6.3796067237854, 'learning_rate': 3.734076433121019e-05, 'epoch': 1.02}
{'loss': 0.0974, 'grad_norm': 1.4173623323440552, 'learning_rate': 3.654458598726115e-05, 'epoch': 1.08}
{'loss': 0.1754, 'grad_norm': 5.505937099456787, 'learning_rate': 3.57484076433121e-05, 'epoch': 1.15}
{'loss': 0.1468, 'grad_norm': 4.4118876457214355, 'learning_rate': 3.495222929936306e-05, 'epoch': 1.21}
{'loss': 0.153, 'grad_norm': 17.917333602905273, 'learning_rate': 3.415605095541402e-05, 'epoch': 1.27}
{'loss': 0.1133, 'grad_norm': 2.534349203109741, 'learning_rate': 3.335987261146497e-05, 'epoch': 1.34}
{'loss': 0.125, 'grad_norm': 8.100704193115234, 'learning_rate': 3.256369426751593e-05, 'epoch': 1.4}
{'loss': 0.1178, 'grad_norm': 2.2615535259246826, 'learning_rate': 3.1767515923566885e-05, 'epoch': 1.46}
{'loss': 0.1522, 'grad_norm': 21.261640548706055, 'learning_rate': 3.0971337579617836e-05, 'epoch': 1.53}
{'loss': 0.1157, 'grad_norm': 7.817129611968994, 'learning_rate': 3.0175159235668794e-05, 'epoch': 1.59}
{'loss': 0.1466, 'grad_norm': 4.848369598388672, 'learning_rate': 2.937898089171975e-05, 'epoch': 1.66}
{'loss': 0.1647, 'grad_norm': 8.912065505981445, 'learning_rate': 2.8582802547770704e-05, 'epoch': 1.72}
{'loss': 0.2263, 'grad_norm': 8.409560203552246, 'learning_rate': 2.7786624203821658e-05, 'epoch': 1.78}
{'loss': 0.128, 'grad_norm': 1.6514339447021484, 'learning_rate': 2.6990445859872616e-05, 'epoch': 1.85}
{'loss': 0.1248, 'grad_norm': 4.441678524017334, 'learning_rate': 2.619426751592357e-05, 'epoch': 1.91}
{'loss': 0.1103, 'grad_norm': 8.216238021850586, 'learning_rate': 2.5398089171974526e-05, 'epoch': 1.97}
{'eval_loss': 0.3285324275493622, 'eval_accuracy': 0.8899082568807339, 'eval_runtime': 0.8165, 'eval_samples_per_second': 1068.038, 'eval_steps_per_second': 17.147, 'epoch': 2.0}
{'loss': 0.1314, 'grad_norm': 3.0901646614074707, 'learning_rate': 2.460191082802548e-05, 'epoch': 2.04}
{'loss': 0.0647, 'grad_norm': 8.937211990356445, 'learning_rate': 2.3805732484076435e-05, 'epoch': 2.1}
{'loss': 0.1023, 'grad_norm': 28.64720344543457, 'learning_rate': 2.300955414012739e-05, 'epoch': 2.17}
{'loss': 0.0332, 'grad_norm': 17.423612594604492, 'learning_rate': 2.2213375796178344e-05, 'epoch': 2.23}
{'loss': 0.0251, 'grad_norm': 0.0777067169547081, 'learning_rate': 2.1417197452229302e-05, 'epoch': 2.29}
{'loss': 0.0195, 'grad_norm': 11.155179023742676, 'learning_rate': 2.0621019108280257e-05, 'epoch': 2.36}
{'loss': 0.099, 'grad_norm': 5.509872913360596, 'learning_rate': 1.982484076433121e-05, 'epoch': 2.42}
{'loss': 0.1248, 'grad_norm': 19.851064682006836, 'learning_rate': 1.902866242038217e-05, 'epoch': 2.48}
{'loss': 0.0305, 'grad_norm': 5.2410712242126465, 'learning_rate': 1.823248407643312e-05, 'epoch': 2.55}
{'loss': 0.071, 'grad_norm': 0.12504814565181732, 'learning_rate': 1.7436305732484075e-05, 'epoch': 2.61}
{'loss': 0.0591, 'grad_norm': 2.7684967517852783, 'learning_rate': 1.6640127388535033e-05, 'epoch': 2.68}
{'loss': 0.0759, 'grad_norm': 4.057375431060791, 'learning_rate': 1.5843949044585988e-05, 'epoch': 2.74}
{'loss': 0.0369, 'grad_norm': 14.202961921691895, 'learning_rate': 1.5047770700636943e-05, 'epoch': 2.8}
{'loss': 0.0563, 'grad_norm': 1.988969087600708, 'learning_rate': 1.4251592356687899e-05, 'epoch': 2.87}
{'loss': 0.024, 'grad_norm': 0.13665416836738586, 'learning_rate': 1.3455414012738854e-05, 'epoch': 2.93}
{'loss': 0.0293, 'grad_norm': 0.052379731088876724, 'learning_rate': 1.265923566878981e-05, 'epoch': 2.99}
{'eval_loss': 0.46311452984809875, 'eval_accuracy': 0.8979357798165137, 'eval_runtime': 0.8213, 'eval_samples_per_second': 1061.688, 'eval_steps_per_second': 17.045, 'epoch': 3.0}
{'loss': 0.023, 'grad_norm': 3.2186734676361084, 'learning_rate': 1.1863057324840765e-05, 'epoch': 3.06}
{'loss': 0.0271, 'grad_norm': 0.042901284992694855, 'learning_rate': 1.1066878980891721e-05, 'epoch': 3.12}
{'loss': 0.0046, 'grad_norm': 8.550307273864746, 'learning_rate': 1.0270700636942676e-05, 'epoch': 3.18}
{'loss': 0.0327, 'grad_norm': 4.096978664398193, 'learning_rate': 9.474522292993632e-06, 'epoch': 3.25}
{'loss': 0.0345, 'grad_norm': 2.926208257675171, 'learning_rate': 8.678343949044587e-06, 'epoch': 3.31}
{'loss': 0.0247, 'grad_norm': 5.882879734039307, 'learning_rate': 7.882165605095541e-06, 'epoch': 3.38}
{'loss': 0.0062, 'grad_norm': 0.039013274013996124, 'learning_rate': 7.085987261146497e-06, 'epoch': 3.44}
{'loss': 0.022, 'grad_norm': 0.02370677888393402, 'learning_rate': 6.289808917197452e-06, 'epoch': 3.5}
{'loss': 0.0213, 'grad_norm': 0.02740313857793808, 'learning_rate': 5.493630573248408e-06, 'epoch': 3.57}
{'loss': 0.002, 'grad_norm': 0.04147066920995712, 'learning_rate': 4.697452229299363e-06, 'epoch': 3.63}
{'loss': 0.0445, 'grad_norm': 0.055248185992240906, 'learning_rate': 3.901273885350319e-06, 'epoch': 3.69}
{'loss': 0.0257, 'grad_norm': 0.11611528694629669, 'learning_rate': 3.105095541401274e-06, 'epoch': 3.76}
{'loss': 0.0057, 'grad_norm': 0.019178779795765877, 'learning_rate': 2.3089171974522293e-06, 'epoch': 3.82}
{'loss': 0.0372, 'grad_norm': 0.06640688329935074, 'learning_rate': 1.5127388535031847e-06, 'epoch': 3.89}
{'loss': 0.0046, 'grad_norm': 15.854581832885742, 'learning_rate': 7.165605095541401e-07, 'epoch': 3.95}
{'eval_loss': 0.5307515263557434, 'eval_accuracy': 0.8967889908256881, 'eval_runtime': 0.8254, 'eval_samples_per_second': 1056.493, 'eval_steps_per_second': 16.962, 'epoch': 4.0}
{'train_runtime': 60.1598, 'train_samples_per_second': 332.448, 'train_steps_per_second': 10.439, 'train_loss': 0.14236228798877945, 'epoch': 4.0}
2025-06-30 03:17:56,426 - INFO - Training completed successfully
2025-06-30 03:17:56,624 - INFO - Model moved to CPU and training finished for task: sst2
2025-06-30 03:17:56,628 - INFO - Starting training for task: qnli with seed: 42
2025-06-30 03:17:56,629 - INFO - Config: CFG(model_name='bert-base-uncased', tasks=['sst2', 'qnli'], train_size=5000, eval_size=1000, device='cuda', epochs=4, batch_train=32, batch_eval=64, save_checkpoints=True, checkpoint_dir='checkpoints', wandb_project='direction_aware_fusion', wandb_entity='your_wandb_entity', wandb_run_name='default_run', wandb=True, log_interval=100, seeds=[42, 123, 456], num_seeds=3, seed=42, confidence_interval=0.95, enable_averaging=False, save_individual_runs=True, aggregation_method='mean')
2025-06-30 03:17:56,629 - INFO - CUDA available: Quadro RTX 8000
2025-06-30 03:17:56,833 - INFO - Tokenizer loaded successfully
2025-06-30 03:17:56,834 - INFO - Loading dataset: glue/qnli
2025-06-30 03:17:58,056 - INFO - Dataset loaded. Train size: 104743, Val size: 5463
2025-06-30 03:17:59,360 - INFO - Data preprocessing complete. Train samples: 5000, Val samples: 1000
2025-06-30 03:17:59,361 - INFO - Loading model: bert-base-uncased
2025-06-30 03:17:59,673 - INFO - Model loaded and moved to device: cuda
2025-06-30 03:17:59,674 - INFO - Setting up training arguments
2025-06-30 03:17:59,754 - INFO - Setting up trainer
2025-06-30 03:17:59,768 - INFO - Starting training...
{'loss': 0.7253, 'grad_norm': 4.476837635040283, 'learning_rate': 4.928343949044586e-05, 'epoch': 0.06}
{'loss': 0.6998, 'grad_norm': 7.41101598739624, 'learning_rate': 4.8487261146496814e-05, 'epoch': 0.13}
{'loss': 0.6537, 'grad_norm': 2.370483160018921, 'learning_rate': 4.769108280254777e-05, 'epoch': 0.19}
{'loss': 0.5726, 'grad_norm': 6.484136581420898, 'learning_rate': 4.689490445859872e-05, 'epoch': 0.25}
{'loss': 0.5195, 'grad_norm': 4.210449695587158, 'learning_rate': 4.609872611464968e-05, 'epoch': 0.32}
{'loss': 0.4736, 'grad_norm': 4.003119945526123, 'learning_rate': 4.530254777070064e-05, 'epoch': 0.38}
{'loss': 0.5092, 'grad_norm': 5.686511993408203, 'learning_rate': 4.450636942675159e-05, 'epoch': 0.45}
{'loss': 0.478, 'grad_norm': 4.6252923011779785, 'learning_rate': 4.371019108280255e-05, 'epoch': 0.51}
{'loss': 0.4547, 'grad_norm': 12.148499488830566, 'learning_rate': 4.2914012738853507e-05, 'epoch': 0.57}
{'loss': 0.4629, 'grad_norm': 3.9167375564575195, 'learning_rate': 4.211783439490446e-05, 'epoch': 0.64}
{'loss': 0.4592, 'grad_norm': 5.306561470031738, 'learning_rate': 4.1321656050955416e-05, 'epoch': 0.7}
{'loss': 0.4521, 'grad_norm': 8.00593376159668, 'learning_rate': 4.0525477707006374e-05, 'epoch': 0.76}
{'loss': 0.495, 'grad_norm': 4.248933792114258, 'learning_rate': 3.9729299363057325e-05, 'epoch': 0.83}
{'loss': 0.4392, 'grad_norm': 6.860152244567871, 'learning_rate': 3.893312101910828e-05, 'epoch': 0.89}
{'loss': 0.43, 'grad_norm': 5.637775897979736, 'learning_rate': 3.8136942675159234e-05, 'epoch': 0.96}
{'eval_loss': 0.41922444105148315, 'eval_accuracy': 0.802, 'eval_runtime': 2.0587, 'eval_samples_per_second': 485.745, 'eval_steps_per_second': 7.772, 'epoch': 1.0}
{'loss': 0.3983, 'grad_norm': 3.66280460357666, 'learning_rate': 3.734076433121019e-05, 'epoch': 1.02}
{'loss': 0.263, 'grad_norm': 3.349501132965088, 'learning_rate': 3.654458598726115e-05, 'epoch': 1.08}
{'loss': 0.2813, 'grad_norm': 4.4212188720703125, 'learning_rate': 3.57484076433121e-05, 'epoch': 1.15}
{'loss': 0.2657, 'grad_norm': 4.0093994140625, 'learning_rate': 3.495222929936306e-05, 'epoch': 1.21}
{'loss': 0.2431, 'grad_norm': 3.3949596881866455, 'learning_rate': 3.415605095541402e-05, 'epoch': 1.27}
{'loss': 0.3175, 'grad_norm': 12.268735885620117, 'learning_rate': 3.335987261146497e-05, 'epoch': 1.34}
{'loss': 0.2865, 'grad_norm': 8.756430625915527, 'learning_rate': 3.256369426751593e-05, 'epoch': 1.4}
{'loss': 0.307, 'grad_norm': 4.3815765380859375, 'learning_rate': 3.1767515923566885e-05, 'epoch': 1.46}
{'loss': 0.3037, 'grad_norm': 6.965404033660889, 'learning_rate': 3.0971337579617836e-05, 'epoch': 1.53}
{'loss': 0.2926, 'grad_norm': 5.52490234375, 'learning_rate': 3.0175159235668794e-05, 'epoch': 1.59}
{'loss': 0.2935, 'grad_norm': 6.765702247619629, 'learning_rate': 2.937898089171975e-05, 'epoch': 1.66}
{'loss': 0.3039, 'grad_norm': 4.751073360443115, 'learning_rate': 2.8582802547770704e-05, 'epoch': 1.72}
{'loss': 0.3217, 'grad_norm': 3.68148136138916, 'learning_rate': 2.7786624203821658e-05, 'epoch': 1.78}
{'loss': 0.2532, 'grad_norm': 4.941334247589111, 'learning_rate': 2.6990445859872616e-05, 'epoch': 1.85}
{'loss': 0.2818, 'grad_norm': 7.754546165466309, 'learning_rate': 2.619426751592357e-05, 'epoch': 1.91}
{'loss': 0.2748, 'grad_norm': 3.0505239963531494, 'learning_rate': 2.5398089171974526e-05, 'epoch': 1.97}
{'eval_loss': 0.3646233081817627, 'eval_accuracy': 0.846, 'eval_runtime': 2.0589, 'eval_samples_per_second': 485.685, 'eval_steps_per_second': 7.771, 'epoch': 2.0}
{'loss': 0.1607, 'grad_norm': 3.0068438053131104, 'learning_rate': 2.460191082802548e-05, 'epoch': 2.04}
{'loss': 0.1215, 'grad_norm': 6.677355766296387, 'learning_rate': 2.3805732484076435e-05, 'epoch': 2.1}
{'loss': 0.1303, 'grad_norm': 1.7317668199539185, 'learning_rate': 2.300955414012739e-05, 'epoch': 2.17}
{'loss': 0.0974, 'grad_norm': 5.574918270111084, 'learning_rate': 2.2213375796178344e-05, 'epoch': 2.23}
{'loss': 0.1508, 'grad_norm': 3.0870025157928467, 'learning_rate': 2.1417197452229302e-05, 'epoch': 2.29}
{'loss': 0.1178, 'grad_norm': 1.3823728561401367, 'learning_rate': 2.0621019108280257e-05, 'epoch': 2.36}
{'loss': 0.1644, 'grad_norm': 1.4542176723480225, 'learning_rate': 1.982484076433121e-05, 'epoch': 2.42}
{'loss': 0.1276, 'grad_norm': 5.766689777374268, 'learning_rate': 1.902866242038217e-05, 'epoch': 2.48}
{'loss': 0.1721, 'grad_norm': 4.381641864776611, 'learning_rate': 1.823248407643312e-05, 'epoch': 2.55}
{'loss': 0.1741, 'grad_norm': 2.492112159729004, 'learning_rate': 1.7436305732484075e-05, 'epoch': 2.61}
{'loss': 0.2255, 'grad_norm': 1.270607590675354, 'learning_rate': 1.6640127388535033e-05, 'epoch': 2.68}
{'loss': 0.1584, 'grad_norm': 4.545014381408691, 'learning_rate': 1.5843949044585988e-05, 'epoch': 2.74}
{'loss': 0.138, 'grad_norm': 11.519176483154297, 'learning_rate': 1.5047770700636943e-05, 'epoch': 2.8}
{'loss': 0.1004, 'grad_norm': 1.2304266691207886, 'learning_rate': 1.4251592356687899e-05, 'epoch': 2.87}
{'loss': 0.1201, 'grad_norm': 5.372496604919434, 'learning_rate': 1.3455414012738854e-05, 'epoch': 2.93}
{'loss': 0.1192, 'grad_norm': 3.336508274078369, 'learning_rate': 1.265923566878981e-05, 'epoch': 2.99}
{'eval_loss': 0.5235207676887512, 'eval_accuracy': 0.849, 'eval_runtime': 2.0591, 'eval_samples_per_second': 485.658, 'eval_steps_per_second': 7.771, 'epoch': 3.0}
{'loss': 0.0592, 'grad_norm': 9.772331237792969, 'learning_rate': 1.1863057324840765e-05, 'epoch': 3.06}
{'loss': 0.0744, 'grad_norm': 10.2821044921875, 'learning_rate': 1.1066878980891721e-05, 'epoch': 3.12}
{'loss': 0.0343, 'grad_norm': 1.2150062322616577, 'learning_rate': 1.0270700636942676e-05, 'epoch': 3.18}
{'loss': 0.056, 'grad_norm': 1.295042634010315, 'learning_rate': 9.474522292993632e-06, 'epoch': 3.25}
{'loss': 0.0561, 'grad_norm': 1.3961313962936401, 'learning_rate': 8.678343949044587e-06, 'epoch': 3.31}
{'loss': 0.0972, 'grad_norm': 1.7857547998428345, 'learning_rate': 7.882165605095541e-06, 'epoch': 3.38}
{'loss': 0.0967, 'grad_norm': 0.4528736174106598, 'learning_rate': 7.085987261146497e-06, 'epoch': 3.44}
{'loss': 0.1084, 'grad_norm': 0.23965102434158325, 'learning_rate': 6.289808917197452e-06, 'epoch': 3.5}
{'loss': 0.0758, 'grad_norm': 0.4484293758869171, 'learning_rate': 5.493630573248408e-06, 'epoch': 3.57}
{'loss': 0.0621, 'grad_norm': 0.48334836959838867, 'learning_rate': 4.697452229299363e-06, 'epoch': 3.63}
{'loss': 0.0361, 'grad_norm': 2.170445442199707, 'learning_rate': 3.901273885350319e-06, 'epoch': 3.69}
{'loss': 0.0423, 'grad_norm': 4.394311904907227, 'learning_rate': 3.105095541401274e-06, 'epoch': 3.76}
{'loss': 0.0299, 'grad_norm': 11.84726333618164, 'learning_rate': 2.3089171974522293e-06, 'epoch': 3.82}
{'loss': 0.0798, 'grad_norm': 6.104869365692139, 'learning_rate': 1.5127388535031847e-06, 'epoch': 3.89}
{'loss': 0.1007, 'grad_norm': 0.7331724762916565, 'learning_rate': 7.165605095541401e-07, 'epoch': 3.95}
{'eval_loss': 0.5599679350852966, 'eval_accuracy': 0.846, 'eval_runtime': 2.0584, 'eval_samples_per_second': 485.805, 'eval_steps_per_second': 7.773, 'epoch': 4.0}
{'train_runtime': 132.3912, 'train_samples_per_second': 151.067, 'train_steps_per_second': 4.744, 'train_loss': 0.25276096649230667, 'epoch': 4.0}
2025-06-30 03:20:12,522 - INFO - Training completed successfully
2025-06-30 03:20:12,721 - INFO - Model moved to CPU and training finished for task: qnli
Orthogonal accuracies [0.8967889908256881, 0.426] [0.5114678899082569, 0.846] [0.8715596330275229, 0.77]
CL {'BWT': -0.025229357798165153, 'FWT': 0.34400000000000003, 'Retention%': 97.18670076726343, 'Transfer%': 180.7511737089202} {'BWT': -0.07599999999999996, 'FWT': 0.36009174311926606, 'Retention%': 91.01654846335698, 'Transfer%': 170.4035874439462}

======== GPU REPORT ========

==============NVSMI LOG==============

Timestamp                                 : Mon Jun 30 03:20:27 2025
Driver Version                            : 570.133.20
CUDA Version                              : 12.8

Attached GPUs                             : 1
GPU 00000000:C4:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes
        Process ID                        : 48224
            GPU Utilization               : 85 %
            Memory Utilization            : 42 %
            Max memory usage              : 13740 MiB
            Time                          : 221850 ms
            Is Running                    : 0

Mon Jun 30 03:20:27 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.20             Driver Version: 570.133.20     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Quadro RTX 8000                On  |   00000000:C4:00.0 Off |                    0 |
| 37%   59C    P2             84W /  260W |       1MiB /  46080MiB |     25%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
